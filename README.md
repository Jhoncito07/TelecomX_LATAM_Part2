# üîç Predicci√≥n de Cancelaci√≥n de Clientes (Churn Analysis)

Este proyecto tiene como objetivo identificar los factores que influyen en la cancelaci√≥n de clientes (churn) y construir modelos de clasificaci√≥n que permitan anticipar dicha cancelaci√≥n. Se aplicaron t√©cnicas de preprocesamiento, balanceo de clases, visualizaci√≥n de datos y evaluaci√≥n de modelos para obtener insights accionables.

---

## üìÅ Estructura del Proyecto

- notebook/: An√°lisis exploratorio, limpieza y modelado.
- datos_tratados.csv: Informe en formato CSV.
- README.md: Documentaci√≥n del proyecto.

---

## ‚öô Tecnolog√≠as Utilizadas

- Python 3.10+
- Pandas, NumPy
- Scikit-learn, XGBoost, imbalanced-learn
- Matplotlib, Seaborn

---

## üß™ Flujo de Trabajo

1. *Preprocesamiento*
   - Codificaci√≥n de variables categ√≥ricas con LabelEncoder.
   - Conversi√≥n binaria de la variable objetivo Churn.
   - Eliminaci√≥n de columnas redundantes y valores nulos.

2. *Balanceo de Clases*
   - Se aplic√≥ SMOTE para oversampling y RandomUnderSampler para undersampling.
   - Se verific√≥ la distribuci√≥n antes y despu√©s del balanceo.

3. *Modelado*
   - Modelos entrenados: Logistic Regression, Random Forest, KNN, SVM, XGBoost.
   - Se utiliz√≥ train_test_split con estratificaci√≥n para mantener la proporci√≥n de clases.

4. *Evaluaci√≥n*
   - M√©tricas: F1 Score, Matriz de Confusi√≥n, Classification Report.
   - Visualizaci√≥n de importancia de variables por modelo:
     - Coeficientes (Logistic Regression, SVM)
     - Permutation Importance (KNN)
     - Feature Importance (Random Forest, XGBoost)

5. *Visualizaciones Clave*
   - Boxplots: Tenure y ChargesTotal vs Churn
   - Scatterplot: Relaci√≥n entre Tenure y ChargesTotal coloreado por Churn
   - Heatmap de correlaci√≥n entre variables num√©ricas

---

## üìä Resultados Destacados

| Modelo              | F1 Score (Churn) | Comentario                                               |
|---------------------|------------------|----------------------------------------------------------|
| Random Forest       | ~0.88            | Excelente rendimiento sin necesidad de escalado          |
| XGBoost             | ~0.87            | Precisi√≥n alta y manejo eficaz de relaciones no lineales |
| Logistic Regression | ~0.81            | Buen baseline, f√°cil de interpretar                      |
| SVM (lineal)        | ~0.80            | Similar a regresi√≥n, menos interpretable                 |
| KNN                 | ~0.75            | Sensible a ruido y escala                                |

---

## üéØ Insights Estrat√©gicos

- Clientes con menor antig√ºedad (Tenure) tienen mayor probabilidad de cancelar.
- Contratos mensuales y facturaci√≥n baja est√°n asociados con mayor churn.
- M√©todos de pago autom√°ticos y servicios adicionales como soporte t√©cnico y seguridad en l√≠nea ayudan a retener clientes.

---

## üìå Recomendaciones

- Incentivar contratos de largo plazo con beneficios exclusivos.
- Ofrecer paquetes de bienvenida a nuevos clientes.
- Promover pagos autom√°ticos con bonificaciones.
- Usar modelos predictivos para segmentar clientes en riesgo y aplicar campa√±as personalizadas.

---

## üì• C√≥mo Ejecutar

Puedes ejecutar este proyecto directamente en Google Colab sin necesidad de instalar nada localmente:

üëâ [Abrir en Google Colab](https://colab.research.google.com/)

### Alternativamente, si prefieres ejecutarlo localmente:

```bash
# Clonar el repositorio
git clone https://github.com/Jhoncito07/TelecomX_LATAM_Part2.git

# Instalar dependencias
pip install -r requirements.txt

# Ejecutar el notebook principal
jupyter notebook notebooks/TelecomX_LATAM_Part2.ipynb
